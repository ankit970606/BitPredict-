# -*- coding: utf-8 -*-
"""BitPredict üí∞üìà

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EIKFL9W2INKw5eqv68lFR08YZ4vJCKhW
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# ============================================================================
# STEP 1: LOAD AND EXPLORE DATA
# ============================================================================

# Load the CSV file
file_path = '/content/Bitcoin_5_13_2010-7_12_2010_historical_data_coinmarketcap.csv'
df = pd.read_csv(file_path, sep=';')

# Remove quotes from string values
df = df.apply(lambda x: x.str.replace('"', '') if x.dtype == "object" else x)

# Convert columns to appropriate types
numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'marketCap', 'circulatingSupply']
for col in numeric_columns:
    df[col] = pd.to_numeric(df[col])

# Convert timestamp to datetime
df['timestamp'] = pd.to_datetime(df['timestamp'])
df = df.sort_values('timestamp').reset_index(drop=True)

print("Dataset Info:")
print(f"Total records: {len(df)}")
print(f"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}")
print(f"\nFirst few rows:")
print(df.head())
print(f"\nData shape: {df.shape}")
print(f"\nColumns: {df.columns.tolist()}")

# ============================================================================
# STEP 2: PREPARE DATA FOR LSTM
# ============================================================================

# Select features for training
# We'll use multiple features: close, volume, high, low
features = ['close', 'volume', 'high', 'low']
data = df[features].values

print(f"\n{'='*60}")
print("DATA PREPARATION")
print(f"{'='*60}")
print(f"Selected features: {features}")
print(f"Data shape: {data.shape}")

# Normalize the data (LSTM works better with normalized data)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# We need a separate scaler for the 'close' price (for inverse transform later)
close_scaler = MinMaxScaler(feature_range=(0, 1))
close_scaler.fit(df[['close']].values)

print(f"Data normalized to range [0, 1]")

# ============================================================================
# STEP 3: CREATE SEQUENCES
# ============================================================================

def create_sequences(data, seq_length):
    """
    Create sequences for LSTM training

    Args:
        data: normalized data array
        seq_length: number of time steps to look back

    Returns:
        X: input sequences (features)
        y: target values (next day's close price)
    """
    X, y = [], []

    for i in range(seq_length, len(data)):
        X.append(data[i-seq_length:i])  # Previous seq_length days
        y.append(data[i, 0])  # Next day's close price (index 0 = close)

    return np.array(X), np.array(y)

# Use 60 days to predict the next day
SEQUENCE_LENGTH = 60

X, y = create_sequences(scaled_data, SEQUENCE_LENGTH)

print(f"\n{'='*60}")
print("SEQUENCE CREATION")
print(f"{'='*60}")
print(f"Sequence length (lookback period): {SEQUENCE_LENGTH} days")
print(f"X shape: {X.shape} (samples, time_steps, features)")
print(f"y shape: {y.shape} (samples,)")
print(f"Total sequences created: {len(X)}")

# ============================================================================
# STEP 4: SPLIT DATA INTO TRAIN AND TEST SETS
# ============================================================================

# Use 80% for training, 20% for testing
train_size = int(len(X) * 0.8)

X_train = X[:train_size]
y_train = y[:train_size]
X_test = X[train_size:]
y_test = y[train_size:]

print(f"\n{'='*60}")
print("TRAIN/TEST SPLIT")
print(f"{'='*60}")
print(f"Training samples: {len(X_train)}")
print(f"Testing samples: {len(X_test)}")
print(f"Split ratio: 80/20")

# ============================================================================
# STEP 5: BUILD LSTM MODEL
# ============================================================================

print(f"\n{'='*60}")
print("BUILDING LSTM MODEL")
print(f"{'='*60}")

model = Sequential([
    # First LSTM layer
    LSTM(units=512, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
    Dropout(0.2),

    # Second LSTM layer
    LSTM(units=248, return_sequences=True),
    Dropout(0.2),

    # Third LSTM layer
    LSTM(units=248, return_sequences=True),
    Dropout(0.2),

    # Fourth LSTM layer
    LSTM(units=128, return_sequences=True),
    Dropout(0.2),

    # Fiveth LSTM layer
    LSTM(units=64, return_sequences=False),
    Dropout(0.2),

    # Output layer
    Dense(units=1)
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='mean_squared_error',
    metrics=['mae']
)

print("Model Architecture:")
model.summary()

# ============================================================================
# STEP 6: TRAIN THE MODEL
# ============================================================================

print(f"\n{'='*60}")
print("TRAINING MODEL")
print(f"{'='*60}")

# Callbacks for better training
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.1,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

print("\nTraining completed!")

# ============================================================================
# STEP 7: MAKE PREDICTIONS
# ============================================================================

print(f"\n{'='*60}")
print("MAKING PREDICTIONS")
print(f"{'='*60}")

# Predict on test data
predictions = model.predict(X_test)

# Inverse transform to get actual prices
predictions_actual = close_scaler.inverse_transform(predictions)
y_test_actual = close_scaler.inverse_transform(y_test.reshape(-1, 1))

print(f"Predictions shape: {predictions_actual.shape}")

# ============================================================================
# STEP 8: EVALUATE MODEL
# ============================================================================

print(f"\n{'='*60}")
print("MODEL EVALUATION")
print(f"{'='*60}")

# Calculate metrics
mse = mean_squared_error(y_test_actual, predictions_actual)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_actual, predictions_actual)
mape = np.mean(np.abs((y_test_actual - predictions_actual) / y_test_actual)) * 100

print(f"Root Mean Squared Error (RMSE): ${rmse:.2f}")
print(f"Mean Absolute Error (MAE): ${mae:.2f}")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")

# ============================================================================
# STEP 9: VISUALIZE RESULTS
# ============================================================================

print(f"\n{'='*60}")
print("GENERATING VISUALIZATIONS")
print(f"{'='*60}")

# Plot 1: Training history
plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss During Training')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='Training MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.title('Model MAE During Training')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Plot 2: Predictions vs Actual
plt.figure(figsize=(15, 6))
plt.plot(y_test_actual, label='Actual Price', color='blue', linewidth=2)
plt.plot(predictions_actual, label='Predicted Price', color='red', linewidth=2, alpha=0.7)
plt.title('Bitcoin Price Prediction - Actual vs Predicted', fontsize=16, fontweight='bold')
plt.xlabel('Time Steps', fontsize=12)
plt.ylabel('Price ($)', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Plot 3: Prediction Error
plt.figure(figsize=(15, 5))
error = predictions_actual - y_test_actual

plt.subplot(1, 2, 1)
plt.plot(error, color='purple', linewidth=1.5)
plt.axhline(y=0, color='black', linestyle='--', linewidth=1)
plt.title('Prediction Error Over Time', fontsize=14)
plt.xlabel('Time Steps')
plt.ylabel('Error ($)')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.hist(error, bins=50, color='purple', alpha=0.7, edgecolor='black')
plt.title('Distribution of Prediction Errors', fontsize=14)
plt.xlabel('Error ($)')
plt.ylabel('Frequency')
plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ============================================================================
# STEP 10: PREDICT NEXT DAY'S PRICE
# ============================================================================

print(f"\n{'='*60}")
print("PREDICTING TOMORROW'S PRICE")
print(f"{'='*60}")

# Get the last 60 days of data
last_sequence = scaled_data[-SEQUENCE_LENGTH:]
last_sequence = last_sequence.reshape(1, SEQUENCE_LENGTH, X_train.shape[2])

# Predict next day
next_day_prediction = model.predict(last_sequence)
next_day_price = close_scaler.inverse_transform(next_day_prediction)

print(f"\nLast known price (today): ${df['close'].iloc[-1]:.2f}")
print(f"Predicted price (tomorrow): ${next_day_price[0][0]:.2f}")
print(f"Expected change: ${next_day_price[0][0] - df['close'].iloc[-1]:.2f}")
print(f"Expected change %: {((next_day_price[0][0] / df['close'].iloc[-1]) - 1) * 100:.2f}%")

# ============================================================================
# BONUS: SAVE THE MODEL
# ============================================================================

print(f"\n{'='*60}")
print("SAVING MODEL")
print(f"{'='*60}")

model.save('bitcoin_lstm_model.h5')
print("Model saved as 'bitcoin_lstm_model.h5'")

print(f"\n{'='*60}")
print("ANALYSIS COMPLETE!")
print(f"{'='*60}")
print("\n‚ö†Ô∏è  IMPORTANT DISCLAIMER:")
print("This model is for educational purposes only.")
print("Cryptocurrency prices are highly volatile and influenced by many external factors.")
print("DO NOT use this for actual trading decisions without proper risk management!")
print(f"{'='*60}\n")



